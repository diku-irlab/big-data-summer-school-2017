{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING FOR DATA ANALYTICS\n",
    "__Copenhagen Summer University, 21-25 August 2017__\n",
    "\n",
    "Frederiksberg Campus  \n",
    "BÃ¼lowsvej 17  \n",
    "1870 Frederiksberg  \n",
    "Denmark\n",
    "\n",
    "http://www.big-data.dk/csu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "One of the texts used during this course is:\n",
    "\n",
    "__Deep Time Series Forecasting with Python__  \n",
    "An Intuitive Introduction to Deep Learning for Applied Time Series Modeling  \n",
    "by N.D. Lewis  \n",
    "ISBN-13: 978-1540809087\n",
    "\n",
    "This section covers the general assumptions made about which programming languages and support modules are to be used when attempting to perform the exercises in each chapter. If you want to run these scripts on your own computer, then you will need to install the following:\n",
    "\n",
    "__Python 2.7__  \n",
    "As mentioned in the beginning of the book, all the code presented is intended to work with Python 2, specifically Python 2.7.11. Therefore, we also suggest that you use this or some later version of Python 2.7.\n",
    "\n",
    "If you are new to Python, try installing a Python distributions called `anaconda` to get started. Use the following link to find a [download option for your operating system](https://www.continuum.io/downloads). We highly recommend using `anaconda` as it will make it easier to install the support modules need to follow the exercises from the text book.\n",
    "\n",
    "Furthermore, the exercises in the book use a number of support models. Some support models such as `matplotlib`, `numpy`, `pandas`, `scipy`, and `scikit-learn` are already included in `anaconda`, however others are not. Below is a collection of links where you can find download and installation instructions for the required support modules not included in `anaconda`.\n",
    "\n",
    "\n",
    "+ __Keras__ is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. To install `Keras` you can either [read and follow the instructions from the documentation](https://keras.io/#installation), or you can use `sudo pip install keras`\n",
    "\n",
    "\n",
    "+ __Theano__ is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. If you installed `keras` first, then it might have already installed `theano`. Use `pip list` to check. To install `Theano` please read the documentation for installation on your operating system [here](http://deeplearning.net/software/theano/install.html). However, you should be able to use the following `conda` command `conda install theano pypgu`.\n",
    "\n",
    "\n",
    "+ __nnet-ts__ is a neural network architecture for time series forecasting. This packages relies heavily on `numpy`, `scipy`, `pandas`, `theano` and `keras`. Check on their repositories for how to install them first. Then, try to fetch the package using `sudo pip install nnet-ts`, otherwise you can download the module from GitHub [here](https://github.com/hawk31/nnet-ts).\n",
    "\n",
    "\n",
    "+ __pyneurgen__ provides libraries for use in Python programs to build hybrids of neural networks and genetic algorithms and/or genetic programming. Use `sudo pip install pyneurgen`, otherwise you can download the module [here](https://pypi.python.org/pypi/pyneurgen/0.3.0).\n",
    "\n",
    "\n",
    "+ __neuralpy__ is another neural network module. It might be more difficult to install due to dependencies on specific versions of `numpy` and `matplotlib`. Try using `sudo pip install neuralpy` first. If this does not work then copy this link `https://pypi.python.org/packages/aa/6f/5d4f1c90fd944108d63428a33fae99d931da110cf13a8c64991474d87f90/neuralpy-1.3.0.tar.gz`. Now from a linux terminal use `wget` to download the module. Then unpack the tarball using `tar -xvzf neuralpy-1.3.0.tar.gz`. Finally `cd` into the unpacked directory and run `sudo python setup.py install`. \n",
    "\n",
    "\n",
    "+ __statsmodels__ provides statistical computations and models for Python. Use `sudo pip install statsmodels` or you can download the module [here](https://pypi.python.org/pypi/statsmodels).\n",
    "\n",
    "\n",
    "+ __xlrd__ provides support for extracting data from MS Excel files. Use `sudo pip install xlrd`, otherwise you can download the module [here](https://pypi.python.org/pypi/xlrd).\n",
    "\n",
    "\n",
    "\n",
    "### NOTICE \n",
    "Since random numbers are involved in many of the examples below, the exact results from the book may or may not be reproduced in this worksheet, since that would require the same versions of Python and each of the Python libraries. However, as we will see, the exact results are not necessary to show that the code produces the expected results!\n",
    "\n",
    "### TEST YOUR SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Does this say it is using the Theano backend?__\n",
    "\n",
    "If not, then you need to change the backend in your `keras.json` file. You can read about this in the documentation [here](https://keras.io/backend/). If you are using the AWS server provided then do the following:\n",
    "\n",
    "1. run `cd /home/ubuntu/.keras/`\n",
    "2. now run `ls` and you see a file called `keras.json`\n",
    "3. you need to edit the `\"backend\"` key-value pair in this file\n",
    "4. use `nano keras.json` to open the file\n",
    "5. move the cursor with you keypad and make the correction\n",
    "6. to save and exit press `Ctrl+X`, then `y`, then `Enter`\n",
    "7. finally, check the result with `cat keras.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nnet_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyneurgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import neuralpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
